{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudcard\n",
    "- **loc and iloc :)**\n",
    "    - we will go through this again today\n",
    "- **should we just use pandas in this class or would using both/polars benefit us more in and out of the classroom?**\n",
    "    - I'd say learn both, that's the most benefitial for you out of classroom.\n",
    "    - As far as problem sets and quizzes are concerned, it's fine to use one of the packages.\n",
    "    - I'll mostly use pandas going forward.\n",
    "- **What are some ways to get more familiar with working with python?**\n",
    "    - easy leetcode problems are a good start to learn standard python (no packages)\n",
    "    - you will practice how to work with popular data science packages well enough during class and the problem sets I think\n",
    "- **need to review basic python functions, like skiprows**\n",
    "    - skiprows is an argument of the pd.read_csv function :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Lecture 3</center>\n",
    "## <center>Working with data (step 0) continued</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning objectives\n",
    "By the end of the lecture, you will be able to\n",
    "- filter columns\n",
    "- merge and append data frames\n",
    "- modify a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Pandas and Polars </center>\n",
    "\n",
    "- data are often distributed over multiple files/databases (e.g., csv and excel files, sql databases)\n",
    "- each file/database is read into a pandas dataframe - last lecture\n",
    "- you often need to filter dataframes by selecting specific rows - last lecture\n",
    "- you often need to filter dataframes by selecting specific columns - today\n",
    "- multiple dataframes need to be merged and appended - today\n",
    "- dataframes sometimes need to be modified - today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some notes and advice\n",
    "\n",
    "- **ALWAYS READ THE HELP OF THE METHODS/FUNCTIONS YOU USE!**\n",
    "- stackoverflow is your friend, use it! https://stackoverflow.com/\n",
    "- you can also use generative AI to help you fix bugs\n",
    "    - Gemini is supported by Brown OIT (see here https://go.brown.edu/gemini)\n",
    "- [here](https://docs.pola.rs/user-guide/migration/pandas/) is an excellet review of the syntax differences between pandas and polars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning objectives</font>\n",
    "<font color='LIGHTGRAY'>By the end of the lecture, you will be able to</font>\n",
    "- **filter columns**\n",
    "- <font color='LIGHTGRAY'>merge and append data frames</font>\n",
    "- <font color='LIGHTGRAY'>modify a dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  fnlwgt  education-num          occupation    race  capital-gain  \\\n",
      "0       39   77516             13        Adm-clerical   White          2174   \n",
      "1       50   83311             13     Exec-managerial   White             0   \n",
      "2       38  215646              9   Handlers-cleaners   White             0   \n",
      "3       53  234721              7   Handlers-cleaners   Black             0   \n",
      "4       28  338409             13      Prof-specialty   Black             0   \n",
      "...    ...     ...            ...                 ...     ...           ...   \n",
      "32556   27  257302             12        Tech-support   White             0   \n",
      "32557   40  154374              9   Machine-op-inspct   White             0   \n",
      "32558   58  151910              9        Adm-clerical   White             0   \n",
      "32559   22  201490              9        Adm-clerical   White             0   \n",
      "32560   52  287927              9     Exec-managerial   White         15024   \n",
      "\n",
      "       hours-per-week gross-income  \n",
      "0                  40        <=50K  \n",
      "1                  13        <=50K  \n",
      "2                  40        <=50K  \n",
      "3                  40        <=50K  \n",
      "4                  40        <=50K  \n",
      "...               ...          ...  \n",
      "32556              38        <=50K  \n",
      "32557              40         >50K  \n",
      "32558              40        <=50K  \n",
      "32559              20        <=50K  \n",
      "32560              40         >50K  \n",
      "\n",
      "[32561 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_pd = pd.read_csv('../data/adult_data.csv')\n",
    "\n",
    "columns =  df_pd.columns\n",
    "#print(columns)\n",
    "\n",
    "# select columns by column name\n",
    "#print(df_pd[['age','hours-per-week']])\n",
    "#print(columns[[1,5,7]])\n",
    "#print(df_pd[columns[[1,5,7]]])\n",
    "\n",
    "# select columns by index using iloc\n",
    "#print(df_pd.iloc[:,3])\n",
    "\n",
    "# select columns by index - not standard python indexing\n",
    "#print(df_pd.iloc[:,[3,5,6]])\n",
    "\n",
    "# select columns by index -  standard python indexing\n",
    "#print(df_pd.iloc[:,::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'gross-income']\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "df_pl = pl.read_csv('../data/adult_data.csv')\n",
    "\n",
    "columns =  df_pl.columns\n",
    "print(columns)\n",
    "\n",
    "# select columns by column name\n",
    "#print(df_pl['age','hours-per-week']) \n",
    "#print(df_pl.select(['age','hours-per-week'])) # use .select if you know the column names. it's often more numerically efficient and can be executed parallel \n",
    "#print(columns[1:4]) # indices must be integers or slices\n",
    "#print(df_pl[columns[1:4]])\n",
    "\n",
    "# select columns by index, polars has no .iloc\n",
    "#print(df_pl[:,3])\n",
    "\n",
    "# select columns by index - not standard python indexing but it works\n",
    "#print(df_pl[:,[3,5,6]])\n",
    "\n",
    "# select columns by index -  standard python indexing\n",
    "#print(df_pl[:,::2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning objectives</font>\n",
    "<font color='LIGHTGRAY'>By the end of the lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>filter columns</font>\n",
    "- **merge and append data frames**\n",
    "- <font color='LIGHTGRAY'>modify a dataframe</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to merge dataframes in Pandas?\n",
    "\n",
    "Merge - info on data points are distributed in multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  col1 col2\n",
      "0  ID1     5    y\n",
      "1  ID2     8    j\n",
      "2  ID3     2    w\n",
      "3  ID4     6    b\n",
      "4  ID5     0    a\n",
      "5  ID6     2    b\n",
      "6  ID7     5    t\n",
      "     ID  col3 col2\n",
      "0   ID2    12    q\n",
      "1   ID5    76    u\n",
      "2   ID6    34    e\n",
      "3  ID10    98    l\n",
      "4  ID11    65    p\n"
     ]
    }
   ],
   "source": [
    "# We have two datasets from two hospitals\n",
    "\n",
    "hospital1 = {'ID':['ID1','ID2','ID3','ID4','ID5','ID6','ID7'],'col1':[5,8,2,6,0,2,5],'col2':['y','j','w','b','a','b','t']}\n",
    "df1 = pd.DataFrame(data=hospital1)\n",
    "print(df1)\n",
    "\n",
    "hospital2 = {'ID':['ID2','ID5','ID6','ID10','ID11'],'col3':[12,76,34,98,65],'col2':['q','u','e','l','p']}\n",
    "df2 = pd.DataFrame(data=hospital2)\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  col1 col2_x  col3 col2_y\n",
      "0   ID1   5.0      y   NaN    NaN\n",
      "1  ID10   NaN    NaN  98.0      l\n",
      "2  ID11   NaN    NaN  65.0      p\n",
      "3   ID2   8.0      j  12.0      q\n",
      "4   ID3   2.0      w   NaN    NaN\n",
      "5   ID4   6.0      b   NaN    NaN\n",
      "6   ID5   0.0      a  76.0      u\n",
      "7   ID6   2.0      b  34.0      e\n",
      "8   ID7   5.0      t   NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# we are interested in only patients from hospital1\n",
    "#df_left = df1.merge(df2,how='left',on='ID') # IDs from the left dataframe (df1) are kept\n",
    "#print(df_left)\n",
    "\n",
    "# we are interested in only patients from hospital2\n",
    "#df_right = df1.merge(df2,how='right',on='ID') # IDs from the right dataframe (df2) are kept\n",
    "#df_right = df2.merge(df1,how='left',on='ID')\n",
    "#print(df_right)\n",
    "\n",
    "# we are interested in patiens who were in both hospitals\n",
    "#df_inner = df1.merge(df2,how='inner',on='ID') # merging on IDs present in both dataframes\n",
    "#print(df_inner)\n",
    "\n",
    "# we are interested in all patients who visited at least one of the hospitals\n",
    "df_outer = df1.merge(df2,how='outer',on='ID')  # merging on IDs present in any dataframe\n",
    "print(df_outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to append dataframes in pandas?\n",
    "\n",
    "Append - new data comes in over a period of time. E.g., one file per month/quarter/fiscal year etc.\n",
    "\n",
    "You want to combine these files into one data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID col1 col2  col3\n",
      "0    ID1    5    y   NaN\n",
      "1    ID2    8    j   NaN\n",
      "2    ID3    2    w   NaN\n",
      "3    ID4    6    b   NaN\n",
      "4    ID5    0    a   NaN\n",
      "5    ID6    2    b   NaN\n",
      "6    ID7    5    t   NaN\n",
      "7    ID2  NaN    q  12.0\n",
      "8    ID5  NaN    u  76.0\n",
      "9    ID6  NaN    e  34.0\n",
      "10  ID10  NaN    l  98.0\n",
      "11  ID11  NaN    p  65.0\n",
      "12  ID23   rt   23   NaN\n",
      "13  ID94    h   86   NaN\n",
      "14  ID56   st   23   NaN\n",
      "15  ID17   ne   78   NaN\n"
     ]
    }
   ],
   "source": [
    "#df_append = pd.concat([df1,df2]) # note that rows with ID2, ID5, and ID6  are duplicated! Indices are duplicated too.\n",
    "#print(df_append)\n",
    "\n",
    "#df_append = pd.concat([df1,df2],ignore_index=True) # note that rows with ID2, ID5, and ID6  are duplicated! \n",
    "#print(df_append)\n",
    "\n",
    "d3 = {'ID':['ID23','ID94','ID56','ID17'],'col1':['rt','h','st','ne'],'col2':[23,86,23,78]}\n",
    "df3 = pd.DataFrame(data=d3)\n",
    "#print(df3)\n",
    "\n",
    "df_append = pd.concat([df1,df2,df3],ignore_index=True) # multiple dataframes can be appended\n",
    "print(df_append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to merge/join dataframes in Polars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital1 = {'ID':['ID1','ID2','ID3','ID4','ID5','ID6','ID7'],'col1':[5,8,2,6,0,2,5],'col2':['y','j','w','b','a','b','t']}\n",
    "df1 = pl.DataFrame(data=hospital1)\n",
    "#print(df1)\n",
    "\n",
    "hospital2 = {'ID':['ID2','ID5','ID6','ID10','ID11'],'col3':[12,76,34,98,65],'col2':['q','u','e','l','p']}\n",
    "df2 = pl.DataFrame(data=hospital2)\n",
    "#print(df2)\n",
    "\n",
    "\n",
    "# left join\n",
    "#df_left = df1.join(df2,how='left',on='ID') # IDs from the left dataframe (df1) are kept\n",
    "#print(df_left)\n",
    "\n",
    "# right join\n",
    "#df_right = df1.join(df2,how='right',on='ID') # IDs from the right dataframe (df2) are kept\n",
    "#df_right = df2.join(df1,how='left',on='ID')\n",
    "#print(df_right)\n",
    "\n",
    "# inner join\n",
    "#df_inner = df1.join(df2,how='inner',on='ID') # merging on IDs present in both dataframes\n",
    "#print(df_inner)\n",
    "\n",
    "# outer join is called a full join\n",
    "#df_outer = df1.join(df2,how='full',on='ID')  # merging on IDs present in any dataframe\n",
    "#print(df_outer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_data_1 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "\n",
    "raw_data_2 = {\n",
    "        'subject_id': ['6', '7', '8', '9', '10'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "\n",
    "raw_data_3 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "\n",
    "# Create three data frames from raw_data_1, 2, and 3.\n",
    "# Append the first two data frames and assign it to df_append.\n",
    "# Merge the third data frame with df_append such that only subject_ids from df_append are present. \n",
    "# Assign the new data frame to df_merge. \n",
    "# How many rows and columns do we have in df_merge?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Always check that the resulting dataframe is what you wanted to end up with!\n",
    "- small toy datasets are ideal to test your code.\n",
    "\n",
    "### If you need to do a more complicated dataframe operations, check out pd.concat() and pl.concat()!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning objectives</font>\n",
    "<font color='LIGHTGRAY'>By the end of the lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>filter columns</font>\n",
    "- <font color='LIGHTGRAY'>merge and append data frames</font>\n",
    "- **modify a dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not EVER overwrite the original data files!\n",
    "## Always save the modified dataframe to a new file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need to modify the dataset?\n",
    "- feature engineering\n",
    "    - generating new features (adding new informative columns) can improve the performance of the ML model\n",
    "- fix dataset issues\n",
    "    - there might be data quality issues that need to be manually fixed\n",
    "    - typos, missing values, etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country gross-income  \\\n",
      "0          2174             0              40   United-States        <=50K   \n",
      "1             0             0              13   United-States        <=50K   \n",
      "2             0             0              40   United-States        <=50K   \n",
      "3             0             0              40   United-States        <=50K   \n",
      "4             0             0              40            Cuba        <=50K   \n",
      "\n",
      "   is immigrant  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4          True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_pd = pd.read_csv('../data/adult_data.csv')\n",
    "#print(df_pd.head())\n",
    "\n",
    "# let's generate a new feature\n",
    "# is immigrant? False (0) if the person's home country is the USA, True (1) otherwise\n",
    "# such a feature has only two categories but it might be pretty informative for some purposes\n",
    "df_pd['is immigrant'] = df_pd['native-country'] != ' United-States'\n",
    "\n",
    "print(df_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mud card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (data1030)",
   "language": "python",
   "name": "data1030"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
