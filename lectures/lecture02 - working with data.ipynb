{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudcard\n",
    "- **The muddiest part for me was classifying different problems (regression, binary, etc). It isn't always clear which approach is best.**\n",
    "- **I struggled with the classification of which type of target variable to use in different situations**\n",
    "    - Yes, that's a pretty tough question and there is no \"one answer fits all\" solution generally because a problem can be phrased as various different supervised ML problems.\n",
    "    - Always consider what you plan to do with the ML model once it is deployed and figure out what sort of supervised ML problem best suits your needs.\n",
    "- **I'm still a bit confused about the ML pipeline.**\n",
    "- **I think the ML pipeline was the most muddiest just out out familiarity**\n",
    "    - We will go through each step in detail so don't worry about it.\n",
    "- **What to choose for the project? What are the stuffs I need to consider for it.**\n",
    "    - I'll send out an announcement about this in a few days.\n",
    "- **For coding, this course use Python, but my undergraduate courses all used R.**\n",
    "    - We start slow so you could use the first few weeks of the term to pick up python.\n",
    "    - If that's not something you'd like to do, consider dropping the course.\n",
    "- **So for the final project, is it possible to show/give us an example of what is expected for us to show?**\n",
    "    - Yes, there is a final reports folder in the course repo which contains a couple of great final reports from previous years.\n",
    "- **I was struggling a bit with the feature matrix and understanding the difference between that and target variables.**\n",
    "    - The target variable is always the variable you want to predict with the ML model. All other variables are usually in the feature matrix.\n",
    "    - There are some exceptions to it like unique IDs or group IDs, we will cover those later.\n",
    "- **About the target variable concept, i believe including more example will be better for us to understand**\n",
    "    - I'd consider it a responsible use of GenAI to ask it for more examples of each type of supervised ML problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Lecture 2</center>\n",
    "## <center>Working with data (step 0)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started with Step 0!\n",
    "\n",
    "## The supervised ML pipeline\n",
    "\n",
    "<span style=\"background-color: #FFFF00\">**0. Data collection/manipulation**: you might have multiple data sources and/or you might have more data than you need</span>\n",
    "   - you need to be able to read in datasets from various sources (like csv, excel, SQL, parquet, etc)\n",
    "   - you need to be able to filter the columns/rows you need for your ML model\n",
    "   - you need to be able to combine the datasets into one dataframe \n",
    "\n",
    "**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to be transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "**4. Choose an evaluation metric**: depends on the priorities of the stakeholders\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "**6. Tune the hyperparameters of your ML models (aka cross-validation or hyperparameter tuning)**\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "**7. Interpret your model**: black boxes are often not useful\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "By the end of the lecture, you will be able to\n",
    "- list main issues with data selection and collection\n",
    "- use pandas/polars to read in a dataset\n",
    "- filter rows of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='LIGHTGRAY'> Learning objectives </font>\n",
    "<font color='LIGHTGRAY'>By the end of the lecture, you will be able to </font>\n",
    "- **list main issues with data selection and collection** \n",
    "- <font color='LIGHTGRAY'>use pandas/polars to read in a dataset </font>\n",
    "- <font color='LIGHTGRAY'>filter rows of a dataframe</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection and collection issues\n",
    "- the field is called **DATA** science for a reason!\n",
    "    - data is the most important part of data science\n",
    "    - the quality and quantity of data determines if a project is feasible\n",
    "    - it is usually much more valuable than algorithms\n",
    "    - working with data takes up ~80% of a data scientist's time\n",
    "- when you start working on a new project, approach your dataset with healthy skepticism!\n",
    "- ask questions in two main categories:\n",
    "    - is the data appropriate for the problem you are trying to solve?\n",
    "    - is the data accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the dataset appropriate for the purpose?\n",
    "- Can you answer your question with your data?\n",
    "    - medical studies based on white men only, can you use it to diagnose everyone?\n",
    "    - sometimes the answer is no! some diseases can differently impact man vs women or various racial groups\n",
    "    - sometimes the answer is yes! some diseases manifest the same way in everyone\n",
    "- Is your dataset timely?\n",
    "    - goal: predict covid cases today\n",
    "        - covid changed a lot over the years: spreads easier but symptoms are milder\n",
    "        - covid data from 2020 and 2021 might not be useable today\n",
    "    - goal: predict severe weather events like hurricanes\n",
    "        - there are not many hurricanes in each year so the temptation is to use data going back as far as possible\n",
    "        - hurricanes became more severe and more frequent in recent years\n",
    "        - is it OK to use data from e.g., 1960s to predict hurricanes today?\n",
    "- What biases are there in your dataset?\n",
    "    - your ML model will learn any biases your data has\n",
    "    - gender bias and racial bias are the main things to worry about when dealing with human data\n",
    "- is your dataset legal, ethical, and reliable?\n",
    "    - can you use the dataset legally?\n",
    "        - protected attributes (such as gender or race) often cannot be used especially in finance for example\n",
    "    - ethical usage\n",
    "        - if data is collected for one purpose, can you use it to solve another problem?\n",
    "    - reliability\n",
    "        - are there any conficts of interests that might make the dataset unreliable?\n",
    "        - example: climate data from big oil companies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the dataset accurate?\n",
    "- typos and errors\n",
    "    - mistakes by humans inputting data are extremely common!\n",
    "- Why are there missing values in the dataset?\n",
    "    - could be fine\n",
    "        - some respondents didn't answer all the survey questions\n",
    "        - doctor didn't perform test on all patients\n",
    "    - could be because of instrucment malfunction\n",
    "    - changes in data collection process over time\n",
    "- How are the missing values represented?\n",
    "    - sometimes as np.nan\n",
    "    - sometimes a string like 'missing' or '?'\n",
    "    - sometimes unreasonable values are used\n",
    "- Are the values valid?\n",
    "    - sometimes you'll see incorrect or impossible values\n",
    "    - 6 digit zip codes\n",
    "    - people older than 200 years\n",
    "    - negative numbers for a quantity that can only be non-negative\n",
    "- Duplicate records\n",
    "    - could be due to data entry error or data manipulation error (incorrect merge or append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "- document your dataset!\n",
    "- your future self and anyone else trying to reproduce your work will thank you!\n",
    "- can be as simple as a text file\n",
    "- describe each column in your dataset\n",
    "    - what is described in the column?\n",
    "    - what quantity is measued? does it have a unit?\n",
    "    - what's the range of valid values?\n",
    "    - what possible categories could there be? what does each category mean?\n",
    "    - are there missing values? if there are, why?\n",
    "    - how are the missing values represented?\n",
    "- you will see examples of this already today!\n",
    "- **if the dataset for your final project does not come with documentation, you need to write one!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='LIGHTGRAY'> Learning objectives </font>\n",
    "<font color='LIGHTGRAY'>By the end of the lecture, you will be able to </font>\n",
    "- <font color='LIGHTGRAY'>list main issues with data selection and collection</font>\n",
    "- **use pandas/polars to read in a dataset**\n",
    "- <font color='LIGHTGRAY'>filter rows of a dataframe</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and Polars - why should you care?\n",
    "\n",
    "- **when you work on an ML problem, you might work with data from various sources**\n",
    "    - healthcare data might come from hospitals, insurance companies, state/federal agencies, etc.\n",
    "    - finance data could come from banks, brokerage accounts, social security office, etc.\n",
    "    - **you will need to pull data from all of these different sources and create one combined dataset ready for ML**\n",
    "- **you might also have more data than you need to solve the ML problem**\n",
    "    - in healthcare, you might be interested in people who have a certain symptom, or maybe you are interested in people who visited the ER multiple times\n",
    "    - in finance, you might be required by law to not use sensitive or protected attributes eventhough you have access to them\n",
    "    - **you need to filter out the rows and columns you need**\n",
    "- packages like pandas and polars make this easy for you "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and polars intro\n",
    "\n",
    "Similarities:\n",
    "- both are packages used for data manipulation and analysis\n",
    "- both use the concept of data frames and series - we will talk about this more later today!\n",
    "- both support reading and writing data in various formats (like CVS, excel, SQL, JSON, etc.)\n",
    "- syntax is similar -- polars uses syntax similar to pandas to make it easier for pandas users to switch over :)\n",
    "\n",
    "Differences:\n",
    "- pandas is more established (released in 2008) so it has a large userbase, great manuals, large community to help with issues\n",
    "- polars is a pretty new package, it has only been around since 2020 but the userbase is rapidly growing\n",
    "- pandas integrates with more packages than polars (although that's changing)\n",
    "- polars is much faster than pandas on large datasets\n",
    "\n",
    "When to use pandas?\n",
    "- Most companies have exensive code bases in pandas and it is unlikely they will switch over anytime soon, it's too costly.\n",
    "- If you work with small to medium datasets and computational speed and memory efficiency are not that critical, pandas is fine.\n",
    "\n",
    "When to use polars?\n",
    "- If you work on large datasets.\n",
    "- If computational speed and memory efficiency are mission-critical\n",
    "\n",
    "Keep in mind that you can use both packages to make the best of both worlds!\n",
    "- Use polars to perform the heavy computations!\n",
    "- Use polars.to_pandas() and polars.from_pandas() to convert dataframes as needed!\n",
    "\n",
    "Check out [this](https://docs.pola.rs/user-guide/migration/pandas/) site to see how you can convert pandas code to polars.\n",
    "\n",
    "Check out [this](https://docs.pola.rs/user-guide/ecosystem/) site for a list of libraries and tools that support polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          workclass  fnlwgt    education  education-num  \\\n",
      "0       39          State-gov   77516    Bachelors             13   \n",
      "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
      "2       38            Private  215646      HS-grad              9   \n",
      "3       53            Private  234721         11th              7   \n",
      "4       28            Private  338409    Bachelors             13   \n",
      "...    ...                ...     ...          ...            ...   \n",
      "32556   27            Private  257302   Assoc-acdm             12   \n",
      "32557   40            Private  154374      HS-grad              9   \n",
      "32558   58            Private  151910      HS-grad              9   \n",
      "32559   22            Private  201490      HS-grad              9   \n",
      "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
      "\n",
      "            marital-status          occupation    relationship    race  \\\n",
      "0            Never-married        Adm-clerical   Not-in-family   White   \n",
      "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
      "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
      "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
      "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
      "...                    ...                 ...             ...     ...   \n",
      "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
      "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
      "32558              Widowed        Adm-clerical       Unmarried   White   \n",
      "32559        Never-married        Adm-clerical       Own-child   White   \n",
      "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
      "0         Male          2174             0              40   United-States   \n",
      "1         Male             0             0              13   United-States   \n",
      "2         Male             0             0              40   United-States   \n",
      "3         Male             0             0              40   United-States   \n",
      "4       Female             0             0              40            Cuba   \n",
      "...        ...           ...           ...             ...             ...   \n",
      "32556   Female             0             0              38   United-States   \n",
      "32557     Male             0             0              40   United-States   \n",
      "32558   Female             0             0              40   United-States   \n",
      "32559     Male             0             0              20   United-States   \n",
      "32560   Female         15024             0              40   United-States   \n",
      "\n",
      "      gross-income  \n",
      "0            <=50K  \n",
      "1            <=50K  \n",
      "2            <=50K  \n",
      "3            <=50K  \n",
      "4            <=50K  \n",
      "...            ...  \n",
      "32556        <=50K  \n",
      "32557         >50K  \n",
      "32558        <=50K  \n",
      "32559        <=50K  \n",
      "32560         >50K  \n",
      "\n",
      "[32561 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# how to read in a database into a dataframe and basic dataframe structure\n",
    "import pandas as pd\n",
    "\n",
    "# load data from a csv file\n",
    "df_pd = pd.read_csv('../data/adult_data.csv') # there are also pd.read_excel(), and pd.read_sql()\n",
    "\n",
    "print(df_pd)\n",
    "#help(df_pd.head)\n",
    "#print(df_pd.head()) # by default, shows the first five rows but check help(df+pd.head) to specify the number of rows to show\n",
    "#print(df_pd.shape) # the shape of your dataframe (number of rows, number of columns)\n",
    "#print(df_pd.shape[0]) # number of rows\n",
    "#print(df_pd.shape[1]) # number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to read in a database into a dataframe and basic dataframe structure\n",
    "import polars as pl\n",
    "\n",
    "# load data from a csv file\n",
    "df_pl = pl.read_csv('../data/adult_data.csv') # there are also pd.read_excel(), and pd.read_sql()\n",
    "# check out pl.scan_csv() too! It is useful if you know you only need to work with certain columns of the dataset\n",
    "# it will only read in the necessary columns!\n",
    "\n",
    "print(df_pl)\n",
    "#help(df_pl.head)\n",
    "#print(df_pl.head()) # by default, shows the first five rows but check help(df_pl.head) to specify the number of rows to show\n",
    "#print(df_pl.shape) # the shape of your dataframe (number of rows, number of columns)\n",
    "#print(df_pl.shape[0]) # number of rows\n",
    "#print(df_pl.shape[1]) # number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "A package is a collection of classes and functions.\n",
    "- a dataframe (pd.DataFrame()) is a pandas class\n",
    "    - a class is the blueprint of how the data should be organized \n",
    "    - classes have methods which can perform operations on the data (e.g., .head(), .shape)\n",
    "- df is an object, an instance of the class.\n",
    "    - when we put data into a class, it becomes an object \n",
    "    - methods are attached to objects \n",
    "       - you cannot call pd.head(), you can only call df.head()\n",
    "- read_csv is a function\n",
    "    - functions are called from the package\n",
    "    - you cannot call df.read_csv, you can only call pd.read_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame structure: both rows and columns are indexed!\n",
    "- index column, no name\n",
    "    - contains the row names\n",
    "    - by default, index is a range object from 0 to number of rows - 1 \n",
    "    - any column can be turned into an index, so indices can be non-number, and also non-unique. more on this later.\n",
    "- polars dataframes do not have an index column by default! rows are indexed by their integer position in the table\n",
    "    - you can add an index column if you'd like though \n",
    "- columns with column names on top in both polars and pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Always print your dataframe to check if it looks good!\n",
    "\n",
    "### Most common reasons it might not look ok:\n",
    "\n",
    "   - the first row is not the column name\n",
    "        - there are rows above the column names that need to be skipped\n",
    "        - there is no column name but by default, pandas assumes the first row is the column name. as a result, \n",
    "          the values of the first row end up as column names.\n",
    "   - character encoding is off\n",
    "   - separator is not comma but some other charachter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the help to find the solution\n",
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "The adult_test.csv file is located in the data folder as well. It is a test set of the adult dataset so you would expect the same column names and generally a similar-looking structure. Read in the file using pandas or polars in the cell below. Make sure the dataframe looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your pandas code below\n",
    "\n",
    "\n",
    "# add your polars code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='LIGHTGRAY'> Learning objectives </font>\n",
    "<font color='LIGHTGRAY'>By the end of the lecture, you will be able to </font>\n",
    "- <font color='LIGHTGRAY'>list main issues with data selection and collection</font>\n",
    "- <font color='LIGHTGRAY'>use pandas/polars to read in a dataset</font>\n",
    "- **filter rows of a dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter rows in pandas\n",
    "- let's assume you have one dataframe to work with but you have too much data and you need to filter out some rows\n",
    "- there are several ways to do that\n",
    "##### 1) Integer-based indexing, numpy arrays are indexed the same way.\n",
    "##### 2) Select rows based on the value of the index column\n",
    "##### 3) select rows based on column condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1) Integer-based indexing, numpy arrays are indexed the same way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# df_pd.iloc[] - for more info, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-integer\n",
    "# iloc is how numpy arrays are indexed (non-standard python indexing)\n",
    "\n",
    "# [start:stop:step] -  general indexing format\n",
    "\n",
    "# start stop step are optional\n",
    "#print(df_pd)\n",
    "#print(df_pd.iloc[:])\n",
    "#print(df_pd.iloc[::])\n",
    "#print(df_pd.iloc[::1])\n",
    "\n",
    "# select one row - 0-based indexing\n",
    "#print(df_pd.iloc[0])\n",
    "\n",
    "# indexing from the end of the data frame\n",
    "#print(df_pd.iloc[-2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# select a slice - stop index not included\n",
    "#print(df_pd.iloc[3:7])\n",
    "\n",
    "# select every second element of the slice - stop index not included\n",
    "#print(df_pd.iloc[3:7:2])\n",
    "\n",
    "#print(df_pd.iloc[3:7:-2]) # return empty dataframe\n",
    "#print(df_pd.iloc[7:3:-2])#  return rows with indices 7 and 5. 3 is the stop so it is not included\n",
    "\n",
    "# can be used to reverse rows\n",
    "#print(df_pd.iloc[::-1])\n",
    "\n",
    "# here is where indexing gets non-standard python\n",
    "# select the 2nd, 5th, and 10th rows\n",
    "#print(df_pd.iloc[[1,4,9]]) # such indexing doesn't work with lists but it works with numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### 2) Select rows based on the value of the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# df_pd.loc[] - for more info, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-label\n",
    "\n",
    "#print(df_pd.index) # the default index when reading in a file is a range index. In this case,\n",
    "                 # .loc and .iloc works ALMOST the same.\n",
    "# one difference:\n",
    "#print(df_pd.loc[3:9:2]) # this selects the 4th, 6th, 8th, 10th rows - the stop element is included!\n",
    "\n",
    "#help(df_pd.set_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_index_age = df_pd.set_index('age',drop=False)\n",
    "\n",
    "#print(df_index_age.head())\n",
    "#print(df_index_age.index)\n",
    "#print(df_index_age.head())\n",
    "\n",
    "print(df_index_age.loc[30].head()) # collect everyone with age 30 - the index is non-unique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3) select rows based on column condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# one condition\n",
    "print(df_pd[df_pd['age']==30].head())\n",
    "# here is the condition: it's a boolean series - series is basically a dataframe with one column\n",
    "#print(df_pd['age']==30)\n",
    "\n",
    "# multiple conditions can be combined with & (and) | (or)\n",
    "#print(df_pd[(df_pd['age']>30)&(df_pd['age']<35)].head())\n",
    "#print(df_pd[(df_pd['age']==90)|(df_pd['native-country']==' Hungary')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter rows in polars\n",
    "### 1) Integer-based indexing\n",
    "- there are no .loc[] or .iloc[] methods in polars but you can still select rows as you would with numpy arrays\n",
    "- df_pl[start:stop:step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example:\n",
    "df_pl[1:10:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Select rows based on column conditions\n",
    "- syntax is similar expect use .filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pl.filter((df_pl['age']==30)&(df_pl['native-country']==' India'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Quiz\n",
    "How many people in adult_data.csv work at least 60 hours a week and have a doctorate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your pandas code below\n",
    "\n",
    "\n",
    "# add your polars code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mud card"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
